import sys
import json
import logging
import os
import re
from pymilvus import connections
from dotenv import load_dotenv
from semantic_retriever import query_rdf_by_keyword
from hybrid_retriever import get_hybrid_retriever
from local_ollama import get_retriever, get_llm_and_agent
from langchain.prompts import PromptTemplate
from langchain_core.messages import HumanMessage, AIMessage

# C·∫•u h√¨nh logging
sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("app.log", encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# K·∫øt n·ªëi Milvus
def connect_milvus():
    try:
        connections.connect(alias='default', host="localhost", port="19530")
        logger.info("ƒê√£ k·∫øt n·ªëi th√†nh c√¥ng ƒë·∫øn Milvus")
        return True
    except Exception as e:
        logger.error(f"L·ªói k·∫øt n·ªëi Milvus: {str(e)}")
        return False

# L∆∞u tr·ªØ l·ªãch s·ª≠ chat
CHAT_HISTORY_FILE = os.path.join(os.path.dirname(__file__), "chat_history.json")
def load_chat_history():
    try:
        with open(CHAT_HISTORY_FILE, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return []
            return json.loads(content)
    except (FileNotFoundError, json.JSONDecodeError):
        with open(CHAT_HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump([], f)
        return []

def save_chat_history(history):
    with open(CHAT_HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

# Prompt template
prompt_template = PromptTemplate(
    input_variables=["input", "chat_history"],
    template="""
    B·∫°n l√† chatbot du l·ªãch th√¥ng minh, gi√∫p ng∆∞·ªùi d√πng t√¨m th√¥ng tin v·ªÅ du l·ªãch Vi·ªát Nam.
    D·ª±a tr√™n c√¢u h·ªèi, th√¥ng tin t·ª´ Milvus (vector search), RDF (tri th·ª©c ng·ªØ nghƒ©a), v√† l·ªãch s·ª≠ tr√≤ chuy·ªán, h√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát chu·∫©n, t·ª± nhi√™n, ng·∫Øn g·ªçn (2-3 c√¢u).
    N·∫øu c√¢u h·ªèi b·∫±ng ti·∫øng Anh, d·ªãch sang ti·∫øng Vi·ªát v√† tr·∫£ l·ªùi.

    - C√¢u h·ªèi: {input}
    - L·ªãch s·ª≠ tr√≤ chuy·ªán: {chat_history}
    """
)

def format_rdf_data(semantic_info):
    """ƒê·ªãnh d·∫°ng d·ªØ li·ªáu RDF ƒë·ªÉ d·ªÖ ƒë·ªçc h∆°n."""
    if not semantic_info:
        return "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu RDF ph√π h·ª£p."
    
    formatted = "D·ªØ li·ªáu RDF thu th·∫≠p ƒë∆∞·ª£c:\n"
    if isinstance(semantic_info, list):
        for idx, item in enumerate(semantic_info, 1):
            if isinstance(item, tuple) and len(item) == 3:
                subject = item[0].split("#")[-1].replace('_', ' ').title()
                predicate = item[1].split("#")[-1].replace('_', ' ').title()
                obj = item[2]
                formatted += f"  {idx}. Ch·ªß th·ªÉ: {subject}\n     V·ªã ng·ªØ: {predicate}\n     ƒê·ªëi t∆∞·ª£ng: {obj}\n"
            else:
                formatted += f"  {idx}. {item}\n"
    else:
        formatted += f"  {semantic_info}\n"
    return formatted

def normalize_text(text):
    """Chu·∫©n h√≥a c√¢u h·ªèi ƒë·ªÉ s·ª≠a l·ªói k√Ω t·ª±."""
    text = re.sub(r'd\?c s\?n', 'ƒë·∫∑c s·∫£n', text)
    text = re.sub(r'H\?i An', 'H·ªôi An', text)
    return text

def main():
    if len(sys.argv) < 2:
        print("Vui l√≤ng cung c·∫•p c√¢u h·ªèi.")
        return

    question = normalize_text(sys.argv[1])
    logger.info(f"Processing question: {question}")

    # K·∫øt n·ªëi Milvus
    if not connect_milvus():
        print("Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn Milvus. Vui l√≤ng ki·ªÉm tra server.")
        return

    # Load .env
    load_dotenv()

    # Kh·ªüi t·∫°o hybrid retriever
    try:
        hybrid_retriever = get_hybrid_retriever(
            collection_name="data_test",
            rdf_path="data/data.rdf"
        )
    except Exception as e:
        logger.error(f"L·ªói kh·ªüi t·∫°o hybrid retriever: {str(e)}")
        print("L·ªói kh·ªüi t·∫°o retriever.")
        return

    # Kh·ªüi t·∫°o Ollama agent
    try:
        retriever = get_retriever(collection_name="data_test")
        agent_executor = get_llm_and_agent(retriever)
    except Exception as e:
        logger.error(f"L·ªói kh·ªüi t·∫°o Ollama agent: {str(e)}")
        print("L·ªói kh·ªüi t·∫°o AI.")
        return

    # Ki·ªÉm tra t·ª´ kh√≥a ƒë·ªÉ truy v·∫•n RDF v√† Milvus
    keyword_trigger = any(word in question.lower() for word in [
        "·∫©m th·ª±c", "m√≥n ƒÉn", "ƒë·∫∑c s·∫£n", "ƒÉn g√¨", "ƒÉn u·ªëng", "m√≥n ngon", "th·ª©c ƒÉn", "qu√°n ƒÉn", "nh√† h√†ng",
        "ƒë·ªãa ƒëi·ªÉm", "th·∫Øng c·∫£nh", "ƒëi·ªÉm ƒë·∫øn", "n·ªïi b·∫≠t", "du l·ªãch", "ƒëi ƒë√¢u", "tham quan",
        "vƒÉn h√≥a", "l·ªÖ h·ªôi", "phong t·ª•c", "truy·ªÅn th·ªëng", "d√¢n t·ªôc", "l·ªãch s·ª≠", "di s·∫£n",
        "tour", "tour du l·ªãch", "g√≥i tour", "l·ªãch tr√¨nh", "h√†nh tr√¨nh", "chuy·∫øn ƒëi", "t√¨m ki·∫øm"
    ])

    # Truy v·∫•n RDF v√† Milvus
    semantic_info = None
    milvus_info = None
    if keyword_trigger:
        try:
            semantic_info = query_rdf_by_keyword(question)
            logger.info(f"Raw RDF data before formatting: {semantic_info}")
            if semantic_info:
                formatted_rdf = format_rdf_data(semantic_info)
                print("‚úÖ D·ªØ li·ªáu RDF li√™n quan:")
                print(formatted_rdf)
                logger.info(f"RDF results:\n{formatted_rdf}")
            else:
                print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y th√¥ng tin RDF ph√π h·ª£p.")
                logger.info("RDF results: Kh√¥ng t√¨m th·∫•y th√¥ng tin RDF ph√π h·ª£p")
        except Exception as e:
            logger.error(f"L·ªói khi truy v·∫•n RDF: {str(e)}")
            print(f"‚ùå L·ªói khi truy v·∫•n RDF: {str(e)}")

        try:
            milvus_results = hybrid_retriever.hybrid_search(question, top_k=3)
            milvus_info = "\n".join([result['text'] for result in milvus_results['combined_results'][:3]])
            logger.info(f"Milvus results: {milvus_info}")
            print("‚úÖ D·ªØ li·ªáu t·ª´ Milvus:")
            print(milvus_info if milvus_info else "‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y th√¥ng tin t·ª´ Milvus.")
        except Exception as e:
            logger.error(f"L·ªói khi truy v·∫•n Milvus: {str(e)}")
            print(f"‚ùå L·ªói khi truy v·∫•n Milvus: {str(e)}")

    # T·∫°o prompt
    prompt = "LU√îN LU√îN tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát chu·∫©n, t·ª± nhi√™n.\n"
    prompt += "K·∫øt h·ª£p th√¥ng tin t·ª´ RDF v√† Milvus ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch chi ti·∫øt, t·ª± nhi√™n, ng·∫Øn g·ªçn (2-3 c√¢u).\n"
    if semantic_info:
        prompt += f"\nTh√¥ng tin t·ª´ RDF:\n{format_rdf_data(semantic_info)}\n"
    if milvus_info:
        prompt += f"\nTh√¥ng tin t·ª´ Milvus:\n{milvus_info}\n"
    prompt += f"\nC√¢u h·ªèi: {question}"

    # L·∫•y l·ªãch s·ª≠ chat
    chat_history = []
    for h in load_chat_history()[-3:]:
        chat_history.append(HumanMessage(content=h['question']))
        chat_history.append(AIMessage(content=h['answer']))

    # G·ªçi agent_executor
    try:
        response = agent_executor.invoke(
            {"input": prompt, "chat_history": chat_history}
        )
        answer = response["output"]
        
        # L∆∞u l·ªãch s·ª≠ chat
        chat_history_data = load_chat_history()
        chat_history_data.append({"question": question, "answer": answer})
        save_chat_history(chat_history_data)
        
        print("\nüìù C√¢u tr·∫£ l·ªùi:")
        print(answer)
    except Exception as e:
        logger.error(f"Error calling AI: {str(e)}")
        print("Xin l·ªói, ƒë√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω c√¢u h·ªèi.")

if __name__ == "__main__":
    main()